% sections/06_resultados.tex
\section{Resultados}
Presentar los resultados obtenidos al aplicar el modelo a los datos de entrada. Incluir gráficos y tablas que ayuden a ilustrar el rendimiento del modelo.
% Este es el corazón de tu sección de resultados.
% Incluye:
% - Métricas de rendimiento: Presenta los valores numéricos de las métricas que definiste en la sección de Metodología (RMSE, MAE, R², etc.) para los conjuntos de entrenamiento y prueba.
% - Gráficos de rendimiento:
%   - Curvas de aprendizaje (pérdida vs. época para entrenamiento y validación).
%   - Gráficos de dispersión de valores predichos vs. valores reales.
%   - Histogramas de errores o residuos.
%   - Si aplicable, mapas de calor o visualizaciones de los resultados georreferenciados.
% - Tablas:
%   - Resumen de las métricas clave.
%   - Comparación del rendimiento de diferentes modelos si probaste varios.
% - Ejemplos de predicciones: Puedes mostrar algunos ejemplos concretos de predicciones del modelo.

% Ejemplo de inclusión de imagen:
% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.8\textwidth]{images/curva_perdida.png} % Asegúrate de la ruta correcta
%     \caption{Curva de pérdida durante el entrenamiento y la validación.}
%     \label{fig:curva_perdida}
% \end{figure}

% Ejemplo de tabla:
% \begin{table}[H]
%     \centering
%     \caption{Métricas de rendimiento del modelo final.}
%     \label{tab:performance_metrics}
%     \begin{tabular}{lcc}
%         \toprule
%         Métrica & Conjunto de Entrenamiento & Conjunto de Prueba \\
%         \midrule
%         RMSE    & \SI{0.123}{tCO2} & \SI{0.156}{tCO2} \\
%         MAE     & \SI{0.098}{tCO2} & \SI{0.112}{tCO2} \\
%         R$^2$   & 0.95            & 0.88             \\
%         \bottomrule
%     \end{tabular}
% \end{table}


\section*{Proceso de entrenamiento y validación del modelo}

El proceso de entrenamiento se estructuró en varias fases orientadas a optimizar tanto la selección de variables predictoras como la robustez del modelo final. En primer lugar, se llevó a cabo una etapa de \textbf{selección de variables}, en la que se evaluaron distintos subconjuntos de características definidos por bloques temáticos con significado ecológico y funcional. Para esta tarea se adoptó un enfoque sistemático basado en la comparación del desempeño predictivo de las distintas combinaciones mediante el algoritmo \texttt{CatBoost}, seleccionado tras pruebas preliminares que mostraron su alta capacidad de ajuste y estabilidad frente a la heterogeneidad de los datos. En todas las configuraciones se mantuvo constante la variable objetivo (carbono capturado) y los parámetros del modelo, de modo que las variaciones en el coeficiente de determinación ($R^2$) y el error cuadrático medio (RMSE) reflejaran exclusivamente la contribución informativa de cada bloque. 

Las configuraciones analizadas incorporaron progresivamente variables relacionadas con las características de la especie, las propiedades edáficas, el terreno, las condiciones climáticas y los índices de vegetación. A partir de los resultados obtenidos, se identificaron los bloques con mayor aporte marginal al rendimiento del modelo, priorizando aquellos cuya inclusión mejoró consistentemente el $R^2$ sin aumentar de forma significativa la complejidad o redundancia del conjunto de predictores.

En una segunda fase, se procedió al \textbf{entrenamiento comparativo de modelos}, implementando un conjunto de algoritmos de aprendizaje supervisado con el fin de contrastar su capacidad predictiva. Entre los estimadores evaluados se incluyeron \texttt{LightGBM}, \texttt{Random Forest}, \texttt{XGBoost}, \texttt{CatBoost}, \texttt{Gradient Boosting}, \texttt{Bagging Regressor}, \texttt{AdaBoost}, \texttt{KNN}, \texttt{MLP}, \texttt{SVR} y \texttt{Bayesian Ridge}. Cada modelo fue entrenado bajo las mismas condiciones experimentales, utilizando las configuraciones de variables seleccionadas en la fase anterior. Esta comparación permitió identificar los algoritmos con mejor ajuste global y menor error de predicción, destacando de nuevo el desempeño de \texttt{CatBoost}.

Posteriormente, se implementó una estrategia de \textbf{stacking}, combinando las predicciones de los modelos individuales mediante un metamodelo de segundo nivel, con el objetivo de aprovechar la complementariedad entre los distintos enfoques y mejorar la capacidad de generalización.

Finalmente, el modelo seleccionado se \textbf{reentrenó con validación cruzada estratificada por grupos}, definidos según el periodo temporal de la observación. Este esquema de validación cruzada por grupos permitió evaluar la estabilidad del modelo frente a periodos no observados durante el entrenamiento, garantizando así su capacidad de generalización temporal y la fiabilidad de las predicciones en escenarios futuros.
 

\subsection{Elección de variables}

Para la selección de variables se adoptó un enfoque sistemático basado en la evaluación del desempeño predictivo de distintos subconjuntos de características, definidos por bloques temáticos con significado ecológico y funcional. Cada combinación de variables se entrenó mediante el algoritmo \texttt{CatBoost}, manteniendo constantes la variable objetivo (carbono capturado) y los parámetros de modelado, de forma que las variaciones en el coeficiente de determinación ($R^2$) y el error cuadrático medio (RMSE) reflejaran exclusivamente la contribución informativa de cada bloque. Las configuraciones incluyeron progresivamente grupos de variables relacionadas con las características de la especie, las propiedades edáficas, el terreno, las condiciones climáticas (temperatura y precipitación) y los índices de vegetación. A partir de la comparación de los resultados, se identificaron los bloques con mayor aporte marginal al rendimiento del modelo, priorizando aquellos cuya incorporación mejoró consistentemente el $R^2$ sin incrementar de forma significativa la complejidad o redundancia del conjunto de predictores.

El análisis comparativo de configuraciones de variables mediante el modelo \texttt{CatBoost} permitió estimar la contribución marginal de cada bloque al poder predictivo del modelo (medido a través de $R^2$ y RMSE). A partir de los resultados, se establecieron las siguientes conclusiones:

\begin{enumerate}
    \item \textbf{Bloque especies.} Incluye variables sobre estado, forma, tratamiento, origen, distribución, composición y fracción de cabida cubierta. Es el bloque con mayor impacto, con incrementos de hasta $+0{,}0054$ en $R^2$. Su efecto es consistente en todas las combinaciones, por lo que se considera esencial.

    \item \textbf{Bloque temperaturas y precipitaciones.} Aporta una mejora sistemática y estable, especialmente en presencia de variables edáficas o de terreno. Los incrementos típicos oscilan entre $+0{,}002$ y $+0{,}005$ en $R^2$. Se recomienda su inclusión por su bajo coste computacional y su valor informativo adicional.

    \item \textbf{Bloque terreno.} Comprende tipo de suelo, rocosidad, orientación, elevación y pendiente. Su efecto es moderado (variaciones de $\pm0{,}001$ en $R^2$) y, aunque aporta cierta estabilidad al modelo, su relevancia es secundaria. Puede incorporarse cuando la disponibilidad de datos lo permita.

    \item \textbf{Bloque índices de vegetación.} (NDII, GNDVI) Produce una ganancia leve y no siempre significativa ($\Delta R^2 \approx 0{,}002$--$0{,}004$), pero tiende a mejorar ligeramente el ajuste medio. Su inclusión es recomendable si los datos están disponibles sin aumentar el coste del pipeline.

    \item \textbf{Bloque soil.} (erosividad, textura, materia orgánica, combustibilidad) Presenta la menor rentabilidad predictiva. Aunque puede mejorar en combinación con variables climáticas, su efecto es inferior al del bloque especies. Se recomienda mantenerlo solo por motivos interpretativos o contextuales.
\end{enumerate}

Aunque el bloque \textit{terreno} no mostró inicialmente una contribución destacada al rendimiento global del modelo, se realizó un análisis adicional para evaluar el efecto individual de cada una de sus variables. Los resultados indicaron que la variable \textit{elevación} presenta una influencia positiva sobre la capacidad predictiva del modelo, mejorando ligeramente las métricas de ajuste. En concreto, la inclusión de \textit{elevación} elevó el coeficiente de determinación a $R^2 = 0{,}8772$ y redujo el error cuadrático medio a $\text{RMSE} = 14{,}36$, frente a los valores obtenidos sin dicha variable ($R^2 = 0{,}8766$, $\text{RMSE} = 14{,}40$). Este incremento, aunque moderado, resulta relevante al tratarse de una única variable adicional (41 predictores frente a 40), lo que sugiere que la altitud puede captar gradientes ambientales asociados a la variabilidad en la captura de carbono que no están plenamente representados por los demás bloques.


\noindent \textbf{Recomendación práctica:} la configuración óptima corresponde a fijas + especies + temperaturas/precipitaciones + índices, con $R^2=0{,}8766$ y 40 variables. Como alternativa ligera, fijas + especies + terreno, $R^2=0{,}8745$ y fijas + especies + índices, $R^2=0{,}8744$ ofrecen un equilibrio adecuado entre rendimiento y complejidad. En términos de prioridad, los bloques deben incluirse en el siguiente orden: \textbf{especies} $\gg$ \textbf{temperaturas y precipitaciones} $>$ \textbf{terreno} $\gtrsim$ \textbf{índices} $>$ \textbf{soil}.

\noindent En conjunto, las variables fijas explican la mayor parte de la varianza, mientras que los bloques adicionales permiten afinar la estimación del carbono capturado. Dado el alto rendimiento base del modelo \texttt{CatBoost}, las mejoras marginales son pequeñas pero consistentes, destacando el valor de las variables de especie y climáticas como componentes clave en la predicción.

Finalmente, se evaluó la sustitución del bloque de variables climáticas (temperaturas y precipitaciones) por el Índice de Martonne, una métrica sintética que integra de forma conjunta la información térmica e hídrica en un solo parámetro. Esta modificación permitió reducir significativamente la dimensionalidad del bloque climático (de ocho variables a una), manteniendo un desempeño prácticamente equivalente. El modelo resultante (\texttt{CatBoost}, 33 variables) alcanzó un $R^2 = 0{,}8721$ y un RMSE de $14{,}66$, valores muy similares a los obtenidos con las variables climáticas explícitas ($R^2 = 0{,8766}$, RMSE $=14{,}40$). Esta equivalencia, junto con la reducción en complejidad y carga computacional, respalda el uso del Índice de Martonne como sustituto eficiente del conjunto de variables de temperatura y precipitación en la modelización de la captura de carbono. 