\section{Implementación del \textit{pipeline}}
El desarrollo y la evaluación de los modelos predictivos se realizaron íntegramente en \textbf{Python}, utilizando librerías como \texttt{scikit-learn}, \texttt{cuML} y \texttt{PyTorch}, junto con implementaciones específicas de \textit{gradient boosting} como \texttt{XGBoost}, \texttt{LightGBM} y \texttt{CatBoost}. El proceso de entrenamiento se llevó a cabo en dos fases diferenciadas. 

Para los modelos entrenados exclusivamente con datos del IFN3 se utilizó un equipo local equipado con un procesador Intel Core i7 y 32~GB de memoria RAM. En cambio, los modelos que empleaban conjuntamente datos del IFN2 e IFN3 se entrenaron en el sistema de computación de alto rendimiento (HPC) de la Universidad de Salamanca. Esta elección se debió a la disponibilidad de tarjetas gráficas Nvidia H100, que permiten acelerar de forma significativa el entrenamiento de aquellos modelos compatibles con ejecución en GPU gracias a su elevada capacidad de paralelización. 

No obstante, cabe señalar que el entrenamiento también podría haberse realizado en un equipo de escritorio convencional equipado con una tarjeta gráfica comercial, ya que los requisitos computacionales del problema no son especialmente elevados.

\subsection{Ingeniería práctica del entrenamiento y la validación}

Desde el punto de vista de la implementación, el proceso de entrenamiento y validación se apoyó fundamentalmente en el ecosistema de \texttt{scikit-learn}, complementado con librerías especializadas para modelos de \textit{gradient boosting}. La gestión de los datos se realizó mediante \texttt{pandas} y \texttt{numpy}, mientras que el cálculo de métricas y estadísticas adicionales del error se apoyó en \texttt{scipy} y los módulos de evaluación de \texttt{sklearn.metrics}.

A partir del conjunto de datos original, se aplicaron filtros de calidad sobre la variable objetivo utilizando operaciones vectorizadas de \texttt{pandas}, eliminando observaciones con valores nulos, inconsistentes o que no cumplían los criterios definidos en la Sección~\ref{subsec:filtradoregistros}. 

La partición de los datos en conjuntos de entrenamiento y prueba se realizó mediante \texttt{GroupShuffleSplit} del módulo \texttt{sklearn.model\_selection}, con una proporción 80/20. Este esquema garantizó que todas las observaciones asociadas a una misma parcela se asignaran íntegramente a un único subconjunto, evitando fugas de información derivadas de la correlación espacial intra-parcela. Sobre el conjunto de entrenamiento se definió una validación cruzada de cinco pliegues utilizando \texttt{GroupKFold}.

El preprocesado de las variables y el ajuste de los modelos se integraron en un único objeto \texttt{Pipeline}, combinando \texttt{ColumnTransformer}, \texttt{SimpleImputer}, \texttt{StandardScaler} y \texttt{OneHotEncoder}. Esta integración aseguró que todas las transformaciones se estimaran exclusivamente con los datos de entrenamiento de cada pliegue durante la validación cruzada. El ajuste de hiperparámetros se llevó a cabo mediante \texttt{GridSearchCV}, definiendo rejillas específicas para cada algoritmo y utilizando el coeficiente de determinación ($R^2$) como métrica de selección.

Los modelos evaluados incluyen implementaciones de \textit{gradient boosting} (\texttt{XGBoost}, \texttt{LightGBM}, \texttt{CatBoost} y \texttt{GradientBoostingRegressor}), métodos basados en \textit{bagging} (\texttt{RandomForestRegressor}, \texttt{BaggingRegressor}), así como modelos de distinta naturaleza como \texttt{MLPRegressor}, \texttt{KNeighborsRegressor}, \texttt{LinearSVR}, \texttt{AdaBoostRegressor} y \texttt{BayesianRidge}. Para cada modelo se calcularon de forma sistemática las métricas de rendimiento sobre el conjunto de prueba: $R^2$, RMSE y MAE, junto con estadísticas adicionales del error absoluto (mediana y moda), almacenándose los resultados en estructuras tabulares para su análisis comparativo.

\subsection{Implementación del \textit{stacking}}

La agregación de modelos mediante \textit{stacking} se implementó de forma manual utilizando utilidades básicas de \texttt{scikit-learn}, con el objetivo de mantener un control estricto sobre el flujo de entrenamiento y validación. A partir de los mejores modelos individuales se generaron predicciones fuera de pliegue (\textit{out-of-fold}, OOF) sobre el conjunto de entrenamiento, empleando el mismo esquema de validación cruzada (\texttt{GroupKFold}).

Estas predicciones OOF se organizaron en matrices de meta-variables mediante \texttt{numpy} y se utilizaron como entrada para el entrenamiento de los metamodelos. En paralelo, cada modelo base se reentrenó sobre la totalidad del conjunto de entrenamiento para generar las correspondientes predicciones sobre el conjunto de test, que se emplearon posteriormente para la evaluación final del \textit{stack}.

Los metamodelos considerados incluyen \texttt{LinearRegression}, \texttt{Ridge}, \\
\texttt{GradientBoostingRegressor}, \texttt{RandomForestRegressor}, \texttt{SVR} con kernel lineal y \texttt{MLPRegressor}. Antes de su ajuste, las meta-variables se estandarizaron mediante \texttt{StandardScaler}, integrando este paso en un \texttt{Pipeline} específico del segundo nivel. La evaluación del \textit{stacking} se realizó exclusivamente sobre el conjunto de test independiente, calculando las métricas habituales ($R^2$, RMSE y MAE) para cada combinación de modelos base y metamodelo.


\subsection{Datos finales de entrenamiento}
\label{subsec:datos_finales_entrenamiento}

Tras aplicar los criterios de elegibilidad y filtrado descritos en la
Sección~\ref{subsec:filtrado_registros}, el conjunto de datos final utilizado
para el ajuste de los modelos queda compuesto por:

\begin{itemize}
    \item \textbf{IFN2:} Total de parcelas = \textbf{88.696}
          \begin{itemize}
              \item Casos con $c4 > c$: \textbf{31.428}
              \item Casos con $carbono\_bruto4 > carbono\_bruto$: \textbf{32.403}
          \end{itemize}

    \item \textbf{IFN3:} Total de parcelas = \textbf{171.157}
          \begin{itemize}
              \item Casos con $fccarb > 20$: \textbf{158.434}
              \item Casos con $fccarb > 20$ y $c4 > c$: \textbf{57.401}
              \item Casos con $fccarb > 20$ y $carbono\_bruto4 > carbono\_bruto$: \textbf{76.617}
          \end{itemize}
\end{itemize}

La Tabla~\ref{tab:resumen_variables} resume las principales estadísticas descriptivas de las variables objetivo utilizadas en el modelado.


\begin{table}[htbp]
    \centering
    \caption{Estadísticos descriptivos del conjunto de datos depurado.}
    \label{tab:resumen_variables}
    \begin{tabular}{lccccc}
        \toprule
        Variable        & N        & Media   & Desv.\ estándar & Mín.     & Máx.       \\
        \midrule
        carbono\_bruto4 & 133\,119 & 20.79 & 35.09 & 0.00 & 420.50 \\
        carbono\_bruto  & 111\,923 & 12.27 & 24.80 & 0.00 & 359.81 \\
        c4              & 103\,790 & 38.83 & 47.27 & 0.48 & 883.46 \\
        c               & 90\,802  & 23.78 & 35.15 & 0.00 & 842.74 \\
        periodo\_agrupado & 103\,785 & 18.47 & 6.47 & 5.00 & 30.00 \\
        \bottomrule
    \end{tabular}
\end{table}

Se observa que la variable \texttt{carbono\_bruto4} presenta una media de 20.79 y una desviación estándar de 35.09, mientras que la variable
\texttt{c4} muestra valores notablemente superiores (media de 38.83 y desviación estándar de 47.27). Podemos encontrar un histograma de la distribución de las variables objetivo en la Figura \ref{fig:histograma_datos_combinado}. 


\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figuras/06_desarrollo_modelo/histogram_c4_post_log.pdf}
        \caption{Histograma de la variable \texttt{c4} en escala logarítmica.}
        \label{fig:hist_c4_sub}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figuras/06_desarrollo_modelo/histogram_carbono_bruto4_post_log.pdf}
        \caption{Histograma de la variable \texttt{carbono\_bruto4} en escala logarítmica.}
        \label{fig:hist_carbono_bruto4_sub}
    \end{subfigure}
    \caption{Histograma de las variables \texttt{c4} y \texttt{carbono\_bruto4} en el conjunto depurado.}
    \label{fig:histograma_datos_combinado}
\end{figure}

En la Figura \ref{fig:distribucion_variables_combinado} podemos ver las distribuciones de las variables objetivo separadas por inventarios, y podemos ver que la variable \texttt{c4} es más dispersa y heterogénea que \texttt{carbono\_bruto4}. En general, una mayor variabilidad en la variable objetivo se traduce en un problema de predicción más complejo, ya que el modelo debe capturar relaciones más inestables y sujetas a mayor ruido.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figuras/06_desarrollo_modelo/distribucion_c4_combinado.pdf}
        \caption{Distribución de la variable \texttt{c4} en escala logarítmica.}
        \label{fig:distribucion_c4_sub}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figuras/06_desarrollo_modelo/distribucion_carbono_bruto4_combinado.pdf}
        \caption{Distribución de la variable \texttt{carbono\_bruto4} en escala logarítmica.}
        \label{fig:distribucion_carbono_bruto4_sub}
    \end{subfigure}
    \caption{Distribución de las variables \texttt{c4} y \texttt{carbono\_bruto4} en el conjunto depurado separadas por inventario.}
    \label{fig:distribucion_variables_combinado}
\end{figure}

Por tanto, incluso antes de evaluar los modelos, es razonable esperar que una misma familia de algoritmos obtenga valores de $R^2$ más elevados y errores más bajos (RMSE, MAE) al predecir \texttt{carbono\_bruto4}, cuya estructura estadística es menos dispersa, que al predecir \texttt{c4}.




\subsubsection{Efecto del periodo sobre el carbono}
\label{subsec:resultados_periodo_anova}

La influencia del \textit{periodo} sobre las variables de carbono se evaluó
mediante ANOVA de un factor. Los análisis realizados \
muestran que el \textit{periodo} ejerce un efecto significativo sobre ambas
variables. En \texttt{c4} se obtuvo un estadístico
\(F = 143.49\) \((p < 0.001)\), mientras que en \texttt{carbono\_bruto4}
el valor fue \(F = 161.08\) \((p < 0.001)\).
Estos resultados indican que las diferencias observadas entre periodos
no son aleatorias, sino que reflejan variaciones sistemáticas asociadas al
momento de muestreo, confirmando que el \textit{periodo} constituye un factor
explicativo relevante en la dinámica del carbono forestal.
