\section{Implementación de los modelos}

El desarrollo y evaluación de los modelos predictivos se realizó íntegramente en \textbf{Python}, utilizando librerías como \texttt{scikit-learn}, \texttt{cuML} y \texttt{PyTorch}, junto con implementaciones específicas de gradient boosting como \texttt{XGBoost}, \texttt{LightGBM} y \texttt{CatBoost}. El entrenamiento se llevó a cabo en dos fases. Para los modelos cuyos datos de entrenamiento provenían solo del IFN3 se uso un equipo local con procesador Intel Core i7 y 32 GB de RAM. Los modelos que usaban los datos del IFN2 e IFN3 se empleo el ordenador de HPC de la Universidad de Salamanca. Esto fue por la posibilidad de usar tarjetas gráficas Nvidia H100, que aceleraba mucho el entrenamiento para los modelos que tienen opción a ejecutarse en una GPU gracias a la posibilidad de paralelización. No obstante, el entrenamiento se podría hacer llevado a cabo en un equipo de escritorio equipado con una tarjeta gráfica comercial, ya que los requisitos no son tan altos.

\subsection{Preparación del conjunto de datos}

La variable objetivo a predecir es el \textbf{carbono bruto acumulado} por parcela (\texttt{carbono\_bruto4}). Para garantizar la consistencia de la muestra, se aplicaron los siguientes filtros:

\begin{itemize}
    \item Se eliminaron observaciones con \texttt{carbono\_bruto4} nulo o igual a cero.
    \item Se retuvieron únicamente aquellas filas donde \texttt{carbono\_bruto} es nulo o estrictamente menor que \texttt{carbono\_bruto4}, evitando duplicidades o inconsistencias entre ambas medidas.
    \item Se restringió el análisis al inventario \texttt{ifn\_id = 3}.
\end{itemize}

Las variables explicativas se seleccionaron a partir de una configuración manual (\texttt{features}) que combina:

\begin{itemize}
    \item Índices de pies por hectárea a distintos diámetros (\texttt{npies\_1}, \texttt{npies\_2}, \dots, \texttt{npies\_70}).
    \item Variables climáticas y edáficas (por ejemplo, \texttt{martonneidx\_id}, \texttt{tipsuelo2\_id}).
    \item Variables topográficas (elevación, pendiente, orientación).
    \item Índices de vegetación y variables de temperatura superficial (\texttt{NDII}, \texttt{EVI}, \texttt{GNDVI}, \texttt{skt\_mean}, \texttt{skt\_std}) en distintas estaciones.
    \item Atributos forestales y estructurales de la masa (\texttt{tipo\_especie}, \texttt{estado\_id}, \texttt{orgmasa1\_id}, \texttt{matorg\_id}, etc.).
\end{itemize}

\subsection{División entrenamiento–prueba y validación cruzada}

Cuando la tabla de datos incluye el identificador de parcela (\texttt{parcela\_id}), la partición entrenamiento–prueba se realiza mediante \texttt{GroupShuffleSplit}, reservando un 20\,\% de las parcelas para prueba y empleando el 80\,\% restante para entrenamiento. De este modo, todas las observaciones de una misma parcela quedan necesariamente en el mismo conjunto, evitando fuga de información.

Sobre el conjunto de entrenamiento se aplica validación cruzada por grupos mediante \texttt{GroupKFold} con 5 particiones, utilizando también \texttt{parcela\_id} como variable de agrupación. En ausencia de esta columna, se recurre a un \texttt{KFold} clásico estratificado en 5 particiones con barajado.

Este esquema permite evaluar la capacidad de generalización del modelo en parcelas no vistas, reduciendo el riesgo de sobreajuste estructural.

\subsection{Preprocesamiento de variables}

El preprocesamiento se implementó con un \texttt{ColumnTransformer} que distingue tres bloques de variables:

\begin{itemize}
    \item \textbf{Variables numéricas generales}: imputación mediante la mediana y escalado con \texttt{StandardScaler}.
    \item \textbf{Variables de densidad de pies} (\texttt{npies\_1}, \dots, \texttt{npies\_70}): imputación mediante un valor constante (0) y posterior escalado. Se tratan como un bloque numérico específico por su naturaleza y rango de valores.
    \item \textbf{Variables categóricas}: imputación por la moda, conversión explícita a cadena de texto y codificación \textit{one-hot} con \texttt{OneHotEncoder}, ignorando categorías desconocidas en el conjunto de prueba.
\end{itemize}

Todo el preprocesado se integra en un \texttt{Pipeline} junto con el modelo de regresión, de manera que la imputación, escalado y codificación se ajustan únicamente sobre el conjunto de entrenamiento y se aplican de forma coherente a validación y prueba.

\subsection{Modelos entrenados y ajuste de hiperparámetros}

Se entrenó un conjunto de modelos base que cubren distintas familias de algoritmos de regresión supervisada:

\begin{itemize}
    \item \textbf{Modelos basados en árboles y ensambles}:
    \begin{itemize}
        \item \texttt{RandomForestRegressor}
        \item \texttt{GradientBoostingRegressor} (GBDT)
        \item \texttt{AdaBoostRegressor}
        \item \texttt{BaggingRegressor} (Bagged Decision Trees)
        \item \texttt{XGBRegressor} (\texttt{XGBoost})
        \item \texttt{LGBMRegressor} (\texttt{LightGBM})
        \item \texttt{CatBoostRegressor} (\texttt{CatBoost})
    \end{itemize}
    \item \textbf{Modelos basados en instancias}:
    \begin{itemize}
        \item \texttt{KNeighborsRegressor} (KNN)
    \end{itemize}
    \item \textbf{Redes neuronales}:
    \begin{itemize}
        \item \texttt{MLPRegressor} (perceptrón multicapa)
    \end{itemize}
    \item \textbf{Máquinas de soporte vectorial}:
    \begin{itemize}
        \item \texttt{LinearSVR} (SVR con kernel lineal)
    \end{itemize}
    \item \textbf{Modelos probabilísticos / bayesianos}:
    \begin{itemize}
        \item \texttt{BayesianRidge} (Bayesian Neural Network en sentido amplio)
    \end{itemize}
\end{itemize}

Para cada modelo se definió un espacio de hiperparámetros específico (número de árboles, profundidad máxima, tasa de aprendizaje, tamaño de vecindad, arquitectura de la red, etc.), y se realizó una búsqueda en rejilla mediante \texttt{GridSearchCV}, usando como métrica de optimización el coeficiente de determinación \(R^2\). La validación interna se llevó a cabo con el mismo esquema de validación cruzada descrito anteriormente (\texttt{GroupKFold} o \texttt{KFold}, según disponibilidad de grupos), y se empleó \texttt{n\_jobs=-1} para explotar el paralelismo multinúcleo.

De cada ajuste se almacenaron:

\begin{itemize}
    \item El mejor estimador (pipeline completo) según el \(R^2\) medio en validación cruzada.
    \item Las métricas en el conjunto de prueba: \(R^2\), RMSE, MAE, así como la mediana del error absoluto y la moda del error absoluto redondeado.
\end{itemize}

\subsection{Ensamblado tipo \textit{stacking}}

Con el fin de explotar la posible complementariedad entre modelos, se implementó un esquema de \textit{stacking} manual basado en predicciones \textit{out-of-fold} (OOF). A partir de los mejores modelos ajustados en la fase anterior (\texttt{slow\_best\_models}), se definieron varias configuraciones de modelos base:

\begin{itemize}
    \item \texttt{['CatBoost', 'LightGBM', 'XGBoost', 'Random Forest', 'GBDT', 'BaggedDT']}
    \item \texttt{['CatBoost', 'LightGBM', 'Random Forest', 'GBDT']}
    \item \texttt{['LightGBM', 'XGBoost', 'GBDT']}
    \item \texttt{['CatBoost', 'Random Forest', 'GBDT']}
    \item \texttt{['LightGBM', 'Random Forest']}
\end{itemize}

Para cada configuración:

\begin{enumerate}
    \item Se generaron predicciones OOF para cada modelo base utilizando el mismo esquema de validación cruzada que en el entrenamiento individual. En cada pliegue, se ajusta un clon del modelo sobre las particiones de entrenamiento y se predice sobre la partición de validación, construyendo así una matriz de meta-características de tamaño \(n_{\text{train}} \times M\), donde \(M\) es el número de modelos base.
    \item Se entrenó de nuevo cada modelo base sobre todo el conjunto de entrenamiento y se obtuvieron sus predicciones sobre el conjunto de prueba, generando una matriz de meta-características de tamaño \(n_{\text{test}} \times M\).
\end{enumerate}

Sobre estas meta-características se ajustaron distintos meta-modelos (\texttt{meta\_models}):

\begin{itemize}
    \item \textbf{Modelos lineales}: \texttt{LinearRegression}, \texttt{Ridge}.
    \item \textbf{Modelos basados en árboles}: \texttt{GradientBoostingRegressor}, \texttt{RandomForestRegressor}.
    \item \textbf{Máquina de vectores soporte}: \texttt{SVR} con kernel lineal.
    \item \textbf{Red neuronal}: \texttt{MLPRegressor} con una capa oculta.
\end{itemize}

Antes del meta-modelo se incluyó un \texttt{StandardScaler} aplicado sobre las meta-características, de forma que se estabiliza el entrenamiento cuando se combinan modelos con escalas de salida diferentes.

Cada combinación \textit{(configuración de bases, meta-modelo)} define un \textit{stack} distinto. Para cada uno de ellos se evaluó el rendimiento en el conjunto de prueba en términos de \(R^2\), RMSE y MAE, seleccionando finalmente el \textbf{stack} con mejor \(R^2\) en prueba (y, en caso de empate, menor RMSE) como modelo final de referencia.

\subsection{Datos finales de entrenamiento}
\label{subsec:datos_finales_entrenamiento}

Tras aplicar los criterios de elegibilidad y filtrado descritos en la
Sección~\ref{subsec:filtrado_registros}, el conjunto de datos final utilizado
para el ajuste de los modelos queda compuesto por:

\begin{itemize}
    \item \textbf{IFN2:} Total de parcelas = \textbf{88.696}
          \begin{itemize}
              \item Casos con $c4 > c$: \textbf{31.428}
              \item Casos con $carbono\_bruto4 > carbono\_bruto$: \textbf{32.403}
          \end{itemize}

    \item \textbf{IFN3:} Total de parcelas = \textbf{171.157}
          \begin{itemize}
              \item Casos con $fccarb > 20$: \textbf{158.434}
              \item Casos con $fccarb > 20$ y $c4 > c$: \textbf{57.401}
              \item Casos con $fccarb > 20$ y $carbono\_bruto4 > carbono\_bruto$: \textbf{76.617}
          \end{itemize}
\end{itemize}

La Tabla~\ref{tab:resumen_variables} resume las principales estadísticas
descriptivas de las variables utilizadas en el modelado, adicionalmente en la Figura~\ref{fig:hist_c4} se muestra la distribución de las mismas.

\begin{table}[htbp]
    \centering
    \caption{Estadísticos descriptivos del conjunto de datos depurado.}
    \label{tab:resumen_variables}
    \begin{tabular}{lrrrrr}
        \toprule
        Variable        & N        & Media   & Desv.\ estándar & Mín.     & Máx.       \\
        \midrule
        carbono\_bruto4 & 136\,325 & 24.6168 & 35.8198         & 0.000327 & 420.498829 \\
        carbono\_bruto  & 114\,485 & 15.9326 & 26.3052         & 0        & 359.805707 \\
        c4              & 105\,714 & 38.3789 & 47.0348         & 0.484695 & 883.462735 \\
        c               & 92\,372  & 23.4399 & 34.9622         & 0        & 842.739088 \\
        periodo         & 105\,709 & 18.3167 & 6.4853          & 0        & 34         \\
        \bottomrule
    \end{tabular}
\end{table}

A partir de los estadísticos descriptivos de la Tabla~\ref{tab:resumen_variables} se observa que la variable
\texttt{carbono\_bruto4} presenta una media de 24.62 y una desviación estándar de 35.82, mientras que la variable
\texttt{c4} muestra valores notablemente superiores (media de 38.38 y desviación estándar de 47.03).

Esta diferencia implica que \texttt{c4} es una variable más dispersa y heterogénea que \texttt{carbono\_bruto4}. En general, una mayor variabilidad en la variable objetivo se traduce en un problema de predicción más complejo, ya que el modelo debe capturar relaciones más inestables y sujetas a mayor ruido.

Por tanto, incluso antes de evaluar los modelos, es razonable esperar que una misma familia de algoritmos obtenga valores de $R^2$ más elevados y errores más bajos (RMSE, MAE) al predecir \texttt{carbono\_bruto4}, cuya estructura estadística es menos dispersa, que al predecir \texttt{c4}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{figuras/histograma_c.png}
    \caption{Distribución de las variables \texttt{c4} y \texttt{carbono\_bruto4} en el conjunto depurado.}
    \label{fig:hist_c4}
\end{figure}

Observamos una clara distribución asimétrica a la izquierda con una larga cola en ambas variables. No existe un factor de escala único que lleve de una variable a la otra porque la generalización a hectárea tiene en cuenta la densidad forestal particular de cada parcela.

\subsubsection{Efecto del periodo sobre el carbono}
\label{subsec:resultados_periodo_anova}

La influencia del \textit{periodo} sobre las variables de carbono se evaluó
mediante ANOVA de un factor. Los análisis realizados \
muestran que el \textit{periodo} ejerce un efecto significativo sobre ambas
variables. En \texttt{c4} se obtuvo un estadístico
\(F = 143.49\) \((p < 0.001)\), mientras que en \texttt{carbono\_bruto4}
el valor fue \(F = 161.08\) \((p < 0.001)\).
Estos resultados indican que las diferencias observadas entre periodos
no son aleatorias, sino que reflejan variaciones sistemáticas asociadas al
momento de muestreo, confirmando que el \textit{periodo} constituye un factor
explicativo relevante en la dinámica del carbono forestal.
