\section{Resultados}
% Aquí es donde analizas lo que significan tus resultados.
% - Interpretación de los resultados: ¿Qué significan los valores de tus métricas? ¿El modelo es bueno, aceptable, o tiene problemas?
% - Comparación con la literatura: ¿Cómo se comparan tus resultados con estudios similares en el campo? ¿Superas, igualas o quedas por debajo de lo esperado? ¿Por qué?
% - Implicaciones: ¿Qué implicaciones tienen tus hallazgos para la predicción de créditos de carbono, la gestión de dehesas, o la toma de decisiones empresariales?
% - Limitaciones del estudio: ¿Qué aspectos no pudo abordar tu modelo o tu metodología? (ej. tamaño del dataset, calidad de los datos, alcance geográfico, factores no considerados).
% - Áreas de mejora: ¿Cómo se podría mejorar el modelo o la investigación en el futuro? (ej. más datos, diferentes modelos de IA, considerar otras variables, integrar datos de otras fuentes).
% - Relevancia práctica: ¿Cómo puede ser utilizado este modelo en el mundo real?

%--------------------------------------------------
\subsection{Resultados}
\label{subsec:resultados_modelos}

En esta sección se presentan los resultados obtenidos por los modelos descritos en la Sección~\ref{subsec:modelosevaluados}. Las tablas de resultados completas se pueden consultar en el \ref{anexo:resultados}.

En conjunto, los resultados obtenidos a lo largo de las cuatro configuraciones de entrenamiento analizadas (IFN3 o IFN2 y 3 como explicativos / variable objetivo en tC o tC/ha) muestran un comportamiento notablemente estable y coherente entre versiones, tanto en términos de capacidad predictiva como de generalización. De forma sistemática, los modelos basados en árboles de decisión y \textit{gradient boosting} son los que alcanzan los mejores niveles de rendimiento, destacando de manera consistente CatBoost y LightGBM como las alternativas más competitivas entre los modelos individuales, independientemente del inventario empleado o de la forma en que se expresa la variable objetivo.

Un aspecto especialmente relevante es la alta similitud entre los valores de $R^2$ obtenidos en validación cruzada y en el conjunto de test, lo que indica que los modelos presentan una buena capacidad de generalización y no muestran síntomas apreciables de sobreajuste. Esta estabilidad se observa tanto en los escenarios con mayor volumen de información (IFN2+IFN3) como en aquellos más simples (IFN3), reforzando la robustez de los enfoques basados en árboles frente a variaciones en la disponibilidad de datos.

La incorporación de esquemas de \textit{stacking} no produce incrementos sustanciales en el coeficiente de determinación respecto a los mejores modelos individuales. No obstante, sí se aprecia una mejora sistemática en el error absoluto medio (MAE), con reducciones que oscilan aproximadamente entre 210 y 371 kg de carbono (o kg/ha), dependiendo del escenario considerado. Esta reducción, aunque moderada en términos relativos, resulta relevante desde un punto de vista práctico, ya que implica predicciones más precisas en el rango de error típico y justifica la consideración del \textit{stacking} como una estrategia complementaria.

En cuanto a la estructura de los ensambles, los mejores resultados se obtienen cuando se combinan modelos base de alta calidad y naturaleza similar (principalmente variantes de \textit{gradient boosting}) y se emplean metamodelos con complejidad moderada, como MLP o SVR lineal. Por el contrario, los \textit{stacks} con pocos modelos base o aquellos que incorporan metamodelos excesivamente flexibles, como Random Forest en el segundo nivel, tienden a ofrecer un rendimiento inferior, probablemente debido a la baja dimensionalidad del espacio de meta-predictores y a un ajuste innecesario del ruido residual.

En síntesis, los resultados confirman que los modelos individuales basados en árboles constituyen una solución sólida y eficiente, mientras que el \textit{stacking} aporta mejoras incrementales principalmente en términos de reducción del error medio.

\begin{table}[H]
\centering
\scriptsize
\caption{Comparación sintética del rendimiento de los modelos según inventarios utilizados y variable objetivo.}
\label{tab:comparativa_global_modelos}
\begin{tabular}{lllrcccc}
\toprule
\textbf{IFN} & \textbf{Variable objetivo} & \textbf{Modelo} & \textbf{Modelos} & $\boldsymbol{R^2}$ & \textbf{RMSE} & \textbf{MAE} \\
\midrule
2 y 3 & tC/ha & LightGBM & 1  & 0.79 & 22.77 & 11.65 \\
2 y 3 & tC/ha & stack1 + MLP & 6   & 0.79 & 22.39 & 11.32 \\
\midrule
2 y 3 & tC & CatBoost & 1  & 0.84 & 13.85 & 6.61 \\
2 y 3 & tC & stack1 + MLP & 6    & 0.85 & 13.76 & 6.40 \\
\midrule
3 & tC/ha & CatBoost & 1  & 0.8598 & 17.7087 & 9.2504 \\
3 & tC/ha & stack1 + MLP & 6     & 0.8656 & 17.3380 & 8.8789 \\
\midrule
3 & tC & LightGBM & 1  & 0.9091 & 10.6623 & 5.4774 \\
3 & tC & stack1 + MLP & 6   & 0.9140 & 10.3723 & 5.2515 \\
\bottomrule
\end{tabular}
\end{table}

La Tabla~\ref{tab:comparativa_global_modelos} sintetiza el rendimiento de los mejores modelos identificados en cada una de las cuatro líneas de entrenamiento consideradas, permitiendo una comparación directa entre inventarios utilizados, variable objetivo y complejidad del modelo. En todos los escenarios se observa un patrón consistente: los modelos individuales basados en \textit{gradient boosting} (LightGBM o CatBoost) ofrecen un rendimiento sólido, que se ve ligeramente mejorado mediante la incorporación de esquemas de \textit{stacking}.

Cuando se emplean conjuntamente los inventarios IFN2 e IFN3 y se predice la variable normalizada en tC/ha, el rendimiento del modelo individual (LightGBM) y del \textit{stack} es prácticamente equivalente en términos de $R^2$, si bien el \textit{stacking} logra una reducción apreciable del MAE, pasando de 11.65 a 11.32 tC/ha. Un comportamiento análogo se observa al predecir carbono total (tC) con IFN2 e IFN3, donde CatBoost alcanza ya valores elevados de $R^2$ (0.84), y el \textit{stack} introduce una mejora moderada pero consistente tanto en $R^2$ como en los errores (RMSE y MAE).

En los escenarios basados exclusivamente en IFN3, los niveles de rendimiento son, en general, superiores. Para la variable en tC/ha, CatBoost explica cerca del 86\% de la varianza observada, mientras que el \textit{stack} incrementa ligeramente este valor y reduce el MAE en aproximadamente 0.37 tC/ha. De forma aún más clara, al predecir carbono total (tC), LightGBM alcanza un $R^2$ superior a 0.91, y el \textit{stacking} vuelve a aportar una mejora incremental, reduciendo el error absoluto medio hasta valores en torno a 5.25 tC.

En conjunto, estos resultados confirman que la mayor ganancia del \textit{stacking} no reside tanto en aumentos sustanciales del $R^2$, sino en una reducción sistemática del error medio, lo que se traduce en predicciones más precisas en términos absolutos. Al mismo tiempo, la tabla pone de manifiesto que los enfoques basados en árboles constituyen una base extremadamente robusta, sobre la que los ensambles apilados actúan como un refinamiento adicional más que como un cambio de paradigma.

\subsection{Síntesis de resultados}
\label{subsec:resultados_sintesis}

A partir del análisis realizado, pueden resumirse las principales conclusiones en los siguientes puntos:

\begin{itemize}
    \item El conjunto de datos depurado muestra una variables objetivos marcadas con gran variabilidad:
          \texttt{carbono\_bruto4} presenta menor dispersión (SD $\approx 36$ tC/ha)
          que \texttt{c4} (SD $\approx 47$ tC/ha), lo que anticipa un problema predictivo más complejo
          para esta última.

    \item El análisis ANOVA confirma que el \textit{periodo} tiene un efecto estadísticamente
          significativo sobre ambas variables de carbono, evidenciando la existencia de variaciones
          temporales sistemáticas relevantes para su modelización.

    \item Entre las estrategias de selección de variables evaluadas (manual, FeatureWiz y mRMR),
          la selección manual, basada en bloques temáticos con coherencia ecológica, ofrece el mejor
          equilibrio entre simplicidad y rendimiento, superando en precisión y error a las selecciones
          automáticas.

    \item Los bloques de variables más informativos son, en orden aproximado de importancia:
          estructura de la masa forestal, características de especie, condiciones edáficas y topográficas,
          índices de vegetación e información climática estacional. La mayor parte del poder predictivo se
          concentra en las características estructurales y de especie.

    \item Los modelos individuales muestran que los métodos basados en árboles y
          \textit{gradient boosting} (CatBoost, LightGBM, XGBoost y GBDT) alcanzan el mejor rendimiento
          global, con valores de $R^2$ de hasta $0.85$ y errores moderados (inferiores al $50\%$ de
          la desviación típica de la variable).

    \item CatBoost destaca como el mejor modelo individual, gracias a su capacidad para capturar
          relaciones no lineales y manejar adecuadamente la complejidad y heterogeneidad de los datos.

    \item Métodos como AdaBoost, KNN o BayesianNN muestran un rendimiento sustancialmente inferior,
          lo que los descarta como candidatos eficaces para este tipo de predicción.

    \item Las técnicas de \textit{stacking} aportan mejoras sistemáticas en el error absoluto medio de los modelos,
          reduciendolos, en la mejor configuración, entorno a un 5\%.
    
    \item El rendimiento del \textit{stacking} depende del meta-modelo: los modelos lineales
          (Regresión Lineal y Ridge) ofrecen combinaciones estables y robustas; los meta-modelos Random
          Forest tienden al sobreajuste; y los meta-modelos moderadamente no lineales (SVR y MLP)
          proporcionan las mayores mejoras.

    \item El modelo desarrollado es capaz de predecir, a partir de las características estructurales,
          ecológicas y ambientales de un cultivo forestal, la cantidad de carbono almacenado
          en un horizonte temporal de entre 5 y 30 años con un nivel elevado de precisión.
          El mejor modelo obtenido se construye mediante un metamodelo \texttt{MLP} combinando los modelos
          \texttt{CatBoost,LightGBM,XGBoost, Random Forest, BaggedDT} y \texttt{GBDT} y alcanza un coeficiente de determinación de
          \textbf{$R^2 = 0.85$}, junto con un error típico de \textbf{RMSE = 13.76 tC} y un error
          medio absoluto de \textbf{MAE = 6.40 tC}.
\end{itemize}
