\section{Resultados}
% Aquí es donde analizas lo que significan tus resultados.
% - Interpretación de los resultados: ¿Qué significan los valores de tus métricas? ¿El modelo es bueno, aceptable, o tiene problemas?
% - Comparación con la literatura: ¿Cómo se comparan tus resultados con estudios similares en el campo? ¿Superas, igualas o quedas por debajo de lo esperado? ¿Por qué?
% - Implicaciones: ¿Qué implicaciones tienen tus hallazgos para la predicción de créditos de carbono, la gestión de dehesas, o la toma de decisiones empresariales?
% - Limitaciones del estudio: ¿Qué aspectos no pudo abordar tu modelo o tu metodología? (ej. tamaño del dataset, calidad de los datos, alcance geográfico, factores no considerados).
% - Áreas de mejora: ¿Cómo se podría mejorar el modelo o la investigación en el futuro? (ej. más datos, diferentes modelos de IA, considerar otras variables, integrar datos de otras fuentes).
% - Relevancia práctica: ¿Cómo puede ser utilizado este modelo en el mundo real?

%--------------------------------------------------
\subsection{Resultados}
\label{subsec:resultados_modelos}

En esta sección se presentan los resultados de los modelos descritos en la
Sección~\ref{subsec:modelos_evaluados}.

\subsubsection{Toneladas de carbono por hectárea}

La Tabla~\ref{tab:resultados_modelos_base} resume las métricas principales para el conjunto de datos que usa el IFN2 y el IFN3 como explicativo y trata de predecir la variable \texttt{c4}, esto es, aquella en tC/ha. En la Tabla~\ref{tab:stack_ifn2_ifn3c} se presentan las métricas para los modelos de \textit{stacking}.

\begin{table}[htbp]
    \centering
    \caption{Resumen del rendimiento de los modelos para la predicción de la variable de carbono en tC/ha con el conjunto de datos que emplea IFN2 e IFN3 como explicativos.}
    \label{tab:resultados_modelos_base}
    \begin{tabular}{lrrrr}
        \toprule
        Modelo            & CV $R^2$ & $R^2_{\text{test}}$ & RMSE$_{\text{test}}$ & MAE$_{\text{test}}$ \\
        \midrule
        Random Forest     & 0.75     & 0.73                & 25.55                & 12.91               \\
        XGBoost           & 0.79     & 0.78                & 22.95                & 11.59               \\
        CatBoost          & 0.80     & 0.78                & 22.99                & 11.61               \\
        \textbf{LightGBM} & 0.79     & 0.79                & 22.77                & 11.65               \\
        GBDT              & 0.79     & 0.78                & 23.01                & 11.66               \\
        BaggedDT          & 0.76     & 0.74                & 25.14                & 13.02               \\
        MLP               & 0.79     & 0.77                & 23.61                & 12.29               \\
        SVR               & 0.58     & 0.55                & 33.07                & 13.71               \\
        BayesianNN        & 0.71     & 0.68                & 28.02                & 14.69               \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{table}[htbp]
    \centering
    \small
    \footnotesize
    % ---------- TABLA ANTERIOR (comentada) ----------
    % \begin{tabular}{lcccc}
    % \hline
    % \textbf{Stack} & \textbf{Bases} & \textbf{Test $R^2$} & \textbf{RMSE} & \textbf{MAE} \\
    % \hline
    % % ---------- STACK 1 ----------
    % stack1\_\_GradientBoosting & 6 & 0.7935 & 21.9173 & 11.3395 \\
    % \textbf{stack1\_\_LinearRegression} & 6 & 0.7967 & 21.7450 & 11.3608 \\
    % stack1\_\_Ridge            & 6 & 0.7967 & 21.7449 & 11.3608 \\
    % stack1\_\_RandomForest     & 6 & 0.7649 & 23.3842 & 12.5924 \\
    % stack1\_\_SVR              & 6 & 0.7946 & 21.8599 & 11.1133 \\
    % stack1\_\_MLP              & 6 & 0.7962 & 21.7746 & 11.2900 \\
    % \hline
    % % ---------- STACK 2 ----------
    % stack2\_\_GradientBoosting & 4 & 0.7936 & 21.9112 & 11.2994 \\
    % \textbf{stack2\_\_LinearRegression} & 4 & 0.7991 & 21.6173 & 11.2304 \\
    % stack2\_\_Ridge            & 4 & 0.7991 & 21.6173 & 11.2304 \\
    % stack2\_\_RandomForest     & 4 & 0.7805 & 22.5927 & 12.1147 \\
    % stack2\_\_SVR              & 4 & 0.7967 & 21.7443 & 11.0286 \\
    % stack2\_\_MLP              & 4 & 0.7978 & 21.6853 & 11.2395 \\
    % \hline
    % % ---------- STACK 3 ----------
    % stack3\_\_GradientBoosting & 3 & 0.8040 & 21.3496 & 11.1647 \\
    % stack3\_\_LinearRegression & 3 & 0.8006 & 21.5331 & 11.2277 \\
    % stack3\_\_Ridge            & 3 & 0.8006 & 21.5330 & 11.2277 \\
    % stack3\_\_RandomForest     & 3 & 0.7856 & 22.3334 & 11.9105 \\
    % \textbf{stack3\_\_SVR}     & 3 & 0.8591 & 17.2998 & 8.6736 \\ % Muy diferente del resto
    % stack3\_\_MLP              & 3 & 0.8004 & 21.5474 & 11.1615 \\
    % \hline
    % % ---------- STACK 4 ----------
    % stack4\_\_GradientBoosting & 3 & 0.8016 & 21.4819 & 11.1555 \\
    % stack4\_\_LinearRegression & 3 & 0.8019 & 21.4631 & 11.1783 \\
    % stack4\_\_Ridge            & 3 & 0.8019 & 21.4631 & 11.1782 \\
    % stack4\_\_RandomForest     & 3 & 0.7922 & 21.9864 & 11.6882 \\
    % \textbf{stack4\_\_SVR}     & \textbf{3} & \textbf{0.8604} & \textbf{17.2203} & \textbf{8.7753} \\
    % stack4\_\_MLP              & 3 & 0.8015 & 21.4845 & 11.0430 \\
    % \hline
    % % ---------- STACK 5 ----------
    % stack5\_\_GradientBoosting & 2 & 0.8014 & 21.4920 & 11.1484 \\
    % stack5\_\_LinearRegression & 2 & 0.8012 & 21.5024 & 11.1741 \\
    % stack5\_\_Ridge            & 2 & 0.8012 & 21.5024 & 11.1741 \\
    % stack5\_\_RandomForest     & 2 & 0.7906 & 22.0694 & 11.6296 \\
    % stack5\_\_SVR              & 2 & 0.7992 & 21.6087 & 10.9512 \\
    % \textbf{stack5\_\_MLP}     & 2 & 0.8017 & 21.4786 & 11.0024 \\
    % \hline
    % \end{tabular}
    % ---------- FIN TABLA ANTERIOR ----------

    \begin{tabular}{llcccc}
        \hline
        \textbf{Stack}  & \textbf{Metamodelo}    & \textbf{Bases} & \textbf{Test $R^2$} & \textbf{RMSE}  & \textbf{MAE}   \\
        \hline
        % ---------- STACK 1 ----------
        stack1 & GradientBoosting & 2 & 0.78 & 23.33 & 11.63 \\
        stack1 & LinearRegression & 2 & 0.79 & 22.77 & 11.61 \\
        stack1 & Ridge            & 2 & 0.79 & 22.77 & 11.61 \\
        stack1 & RandomForest     & 2 & 0.75 & 24.91 & 12.88 \\
        stack1 & SVR              & 2 & 0.78 & 23.11 & 11.37 \\
        stack1 & MLP              & 2 & 0.79 & 22.63 & 11.58 \\
        \hline
        % ---------- STACK 2 ----------
        stack2 & GradientBoosting & 3 & 0.78 & 23.18 & 11.53 \\
        stack2 & LinearRegression & 3 & 0.79 & 22.56 & 11.43 \\
        stack2 & Ridge            & 3 & 0.79 & 22.57 & 11.43 \\
        stack2 & RandomForest     & 3 & 0.75 & 24.45 & 12.35 \\
        stack2 & SVR              & 3 & 0.79 & 22.85 & 11.21 \\
        stack2 & MLP              & 3 & 0.79 & 22.40 & 11.40 \\
        \hline
        % ---------- STACK 3 ----------
        stack3 & GradientBoosting & 4 & 0.78 & 23.21 & 11.45 \\
        stack3 & LinearRegression & 4 & 0.79 & 22.73 & 11.46 \\
        stack3 & Ridge            & 4 & 0.79 & 22.74 & 11.45 \\
        stack3 & RandomForest     & 4 & 0.75 & 24.78 & 12.41 \\
        stack3 & SVR              & 4 & 0.78 & 23.00 & 11.22 \\
        stack3 & MLP              & 4 & 0.79 & 22.78 & 11.34 \\
        \hline
        % ---------- STACK 4 ----------
        stack4 & GradientBoosting & 5 & 0.77 & 23.53 & 11.48 \\
        stack4 & LinearRegression & 5 & 0.79 & 22.60 & 11.42 \\
        stack4 & Ridge            & 5 & 0.79 & 22.60 & 11.41 \\
        stack4 & RandomForest     & 5 & 0.75 & 24.73 & 12.22 \\
        stack4 & SVR              & 5 & 0.79 & 22.87 & 11.18 \\
        stack4 & MLP              & 5 & 0.79 & 22.53 & 11.31 \\
        \hline
        % ---------- STACK 5 ----------
        stack5 & GradientBoosting & 6 & 0.78 & 23.28 & 11.42 \\
        stack5 & LinearRegression & 6 & 0.79 & 22.57 & 11.39 \\
        stack5 & Ridge            & 6 & 0.79 & 22.57 & 11.38 \\
        stack5 & RandomForest     & 6 & 0.76 & 24.15 & 12.03 \\
        stack5 & SVR              & 6 & 0.79 & 22.86 & 11.16 \\
        \textbf{stack5} & \textbf{MLP} & \textbf{6} & \textbf{0.79} & \textbf{22.39} & \textbf{11.32} \\
        \hline
    \end{tabular}
    \caption{Resultados de las diferentes configuraciones de stacking utilizando IFN2 e IFN3 como explicativos de la variable en tC/ha.}
    \label{tab:stack_ifn2_ifn3c}
\end{table}

% De los resultados mostrados en la Tabla~\ref{tab:resultados_modelos23c} se ve que los modelos 
% entrenados tienen, en general, una capacidad de generalización estable pues el rendimiento 
% estimado durante la validación cruzada es muy similar al rendimiento real sobre datos no vistos. 
% Se observa que los modelos basados en árboles de decisión y en \textit{gradient boosting} son los
%  que ofrecen, en general, el mejor equilibrio entre capacidad predictiva y estabilidad. 
%  Métodos como CatBoost, LightGBM, XGBoost o GBDT alcanzan valores de $R^2$ elevados 
%  (superiores al 0.83) y errores de predicción moderados. 
%  Por el contrario, algoritmos como AdaBoost o KNN muestran un rendimiento claramente inferior, 
%  con pérdidas importantes tanto en $R^2$ como en RMSE y MAE.

% En particular, \textbf{CatBoost} destaca como el modelo con mejor rendimiento global, 
% alcanzando un $R^2 = 0.7946$ y un RMSE de $21.7044$ tC/ha. Estos valores implican que el modelo 
% es capaz de explicar una proporción sustancial de la variabilidad del carbono en las parcelas, 
% reduciendo el error típico de predicción a menos de la mitad de la variabilidad natural de la 
% variable (SD $\approx 47$ tC/ha). Esto indica que, dentro de la complejidad inherente al problema, 
% CatBoost logra capturar de manera más eficaz las relaciones no lineales presentes en los datos.

% En la Figura~\ref{fig:scatter_obs_pred_best} se muestran los valores observados
% frente a los predichos para el modelo con mejor desempeño.

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.7\textwidth]{figuras/CatBoost_Professional.png}
%     \caption{Valores observados vs. predichos de \texttt{c4} (tC/ha)para el modelo con mejor rendimiento de los entrenados con IFN2 e IFN3 como explicativos.}
%     \label{fig:scatter_obs_pred_best}
% \end{figure}

\subsubsection{Toneladas de carbono}

La Tabla~\ref{tab:resultados_modelos_base_tc} resume las métricas principales para el conjunto de datos que usa el IFN2 y el IFN3 como explicativo y trata de predecir la variable \texttt{carbono\_bruto4}, esto es, el carbono en toneladas absolutas (no normalizado por hectárea). En la Tabla~\ref{tab:stack_ifn2_ifn3_tc} se encentra lo propio para los modelos stacking.

\begin{table}[htbp]
    \centering
    \caption{Resumen del rendimiento de los modelos para la predicción de la variable de carbono en toneladas (carbono\_bruto4) con el conjunto de datos que emplea IFN2 e IFN3 como explicativos.}
    \label{tab:resultados_modelos_base_tc}
    \begin{tabular}{lrrrr}
        \toprule
        Modelo            & CV $R^2$ & $R^2_{\text{test}}$ & RMSE$_{\text{test}}$ & MAE$_{\text{test}}$ \\
        \midrule
        Random Forest     & 0.81     & 0.82                & 14.95                & 7.14                \\
        XGBoost           & 0.84     & 0.84                & 14.05                & 6.65                \\
        \textbf{CatBoost} & 0.84     & 0.84                & 13.85                & 6.61                \\
        LightGBM          & 0.84     & 0.84                & 14.01                & 6.65                \\
        GBDT              & 0.84     & 0.84                & 14.16                & 6.72                \\
        BaggedDT          & 0.82     & 0.82                & 14.86                & 7.28                \\
        MLP               & 0.83     & 0.83                & 14.41                & 6.93                \\
        SVR               & 0.66     & 0.68                & 19.90                & 8.14                \\
        BayesianNN        & 0.77     & 0.77                & 16.67                & 8.91                \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{table}[htbp]
    \centering
    \small
    \footnotesize
    \begin{tabular}{llcccc}
        \hline
        \textbf{Stack}  & \textbf{Metamodelo}    & \textbf{Bases} & \textbf{Test $R^2$} & \textbf{RMSE}  & \textbf{MAE}  \\
        \hline
        % ---------- STACK 1 ----------
        stack1 & GradientBoosting & 2 & 0.84 & 14.04 & 6.53 \\
        stack1 & LinearRegression & 2 & 0.84 & 13.97 & 6.62 \\
        stack1 & Ridge            & 2 & 0.84 & 13.97 & 6.62 \\
        stack1 & RandomForest     & 2 & 0.81 & 15.13 & 7.27 \\
        stack1 & SVR              & 2 & 0.84 & 14.15 & 6.53 \\
        stack1 & MLP              & 2 & 0.84 & 13.97 & 6.48 \\
        \hline
        % ---------- STACK 2 ----------
        stack2 & GradientBoosting & 3 & 0.84 & 13.98 & 6.52 \\
        stack2 & LinearRegression & 3 & 0.84 & 13.91 & 6.59 \\
        stack2 & Ridge            & 3 & 0.84 & 13.91 & 6.59 \\
        stack2 & RandomForest     & 3 & 0.83 & 14.65 & 7.02 \\
        stack2 & SVR              & 3 & 0.84 & 14.06 & 6.51 \\
        stack2 & MLP              & 3 & 0.84 & 13.91 & 6.51 \\
        \hline
        % ---------- STACK 3 ----------
        stack3 & GradientBoosting & 4 & 0.84 & 13.88 & 6.45 \\
        stack3 & LinearRegression & 4 & 0.85 & 13.81 & 6.56 \\
        stack3 & Ridge            & 4 & 0.85 & 13.81 & 6.56 \\
        stack3 & RandomForest     & 4 & 0.83 & 14.54 & 6.91 \\
        stack3 & SVR              & 4 & 0.84 & 13.97 & 6.47 \\
        stack3 & MLP              & 4 & 0.85 & 13.78 & 6.41 \\
        \hline
        % ---------- STACK 4 ----------
        stack4 & GradientBoosting & 5 & 0.85 & 13.82 & 6.42 \\
        stack4 & LinearRegression & 5 & 0.85 & 13.78 & 6.53 \\
        stack4 & Ridge            & 5 & 0.85 & 13.78 & 6.53 \\
        stack4 & RandomForest     & 5 & 0.84 & 14.24 & 6.75 \\
        stack4 & SVR              & 5 & 0.84 & 13.94 & 6.45 \\
        stack4 & MLP              & 5 & 0.85 & 13.77 & 6.43 \\
        \hline
        % ---------- STACK 5 ----------
        stack5 & GradientBoosting & 6 & 0.85 & 13.81 & 6.42 \\
        stack5 & LinearRegression & 6 & 0.85 & 13.78 & 6.54 \\
        stack5 & Ridge            & 6 & 0.85 & 13.78 & 6.54 \\
        stack5 & RandomForest     & 6 & 0.84 & 14.21 & 6.71 \\
        stack5 & SVR              & 6 & 0.84 & 13.94 & 6.45 \\
        \textbf{stack5} & \textbf{MLP} & \textbf{6} & \textbf{0.85} & \textbf{13.76} & \textbf{6.40} \\
        \hline
    \end{tabular}
    \caption{Resultados de las diferentes configuraciones de stacking utilizando IFN2 e IFN3 como explicativos de la variable en toneladas de carbono.}
    \label{tab:stack_ifn2_ifn3_tc}
\end{table}

% Los resultados muestran un patrón similar al observado en la predicción de carbono por hectárea:
% los modelos basados en \textit{gradient boosting} (CatBoost, LightGBM, XGBoost) obtienen el mejor
% rendimiento, con $R^2$ en torno a 0.84 y RMSE cercano a 14 toneladas. CatBoost destaca nuevamente
% como el modelo individual con mejor rendimiento, alcanzando un RMSE de 13.85 tC.