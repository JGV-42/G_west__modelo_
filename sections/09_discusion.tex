\section{Discusión}
\label{sec:discusion}

Dividiremos las discusión es dos partes muy parecidos, para cada una de las variables objetivo. Luego compararemos brevemente los resultados en conjunto.

\subsection{Discusión sobre la variable objetivo \texttt{c4}}
\label{subsec:discusion_c4}
Comenzando por los modelos individuales, observamos que el modelo LightGBM es el que presenta un mayor valor de $R^2$ ($0.79$) y un menor RMSE ($22.77$ tC/ha), no así un menor MAE ($11.65$ tC/ha), caso en el que los modelos XGBoost ($11.59$ tC/ha) y CatBoost ($11.61$ tC/ha) mejoran ligeramente. Los resultados de estos modelos son muy similares, logrando captar cerca de un $80\%$ de la varianilidad de los datos.  

Mirar a las estadísticas globales de los resultados nos da una idea de la calidad de los modelos, pero en este caso, donde los datos tienen tanta variabilidad, podemos comprobar que esto no resulta del todo útil. En la Figura~\ref{fig:dispersion_densidad_c4} podemos observar la dispersión de las predicciones respecto a los valores reales, junto con una visualización de la densidad de puntos. Observando la figura nos damos cuenta de varias cosas:
\begin{itemize}
    \item Los datos abarcan un gran rango de valores, de $0$ a $900$ tC/ha.
    \item La gran mayoría de los datos se encuentran en el rango de $0$ a $200$ tC/ha.
    \item Podemos ver por los valores de densidad que los valores más abundantes son aquellos cercanos a cero
    \item Mientras que hay casos en los que los valores predichos difieren notablemente de los reales, la línea de mayor densdad se encuentra siguiendo la línea diagonal, lo que indica que el modelo efectivamente captura la tendencia general de los datos.
\end{itemize}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figuras/density_LightGBM_0-300.pdf}
    \caption{Dispersión del modelo LightGBM de las predicciones respecto a los valores reales para la variable objetivo \texttt{c4}. Solo se incluye el rango de valores $[0-300]$ tC/ha.}
    \label{fig:dispersion_densidad_c4}
\end{figure}

Debido a la elevada variabilidad de los datos y a la irregularidad de la distribución respecto a los años (ver Figura~\ref{fig:periodo234}), el modelo no tiene la misma precisión para todos los rangos de valores. En al Figura~\ref{fig:smape_c4} podemos observar el SMAPE para cada uno de los modelos base, junto con un histograma que muestra la distribución del número de valores del conjunto de entrenamiento para cada rango de valores elegidos. Los rangos en los que no hay datos es porque no se disponen de suficientes para hacer el cálculo.

TODO: Meter versión nueva de esta imagen (hay línea que se tapan entre sí) 
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figuras/c4_base_models_SMAPE_RMSE_combined_bins.pdf}
    \caption{SMAPE y RMSE de los modelos base para la variable objetivo \texttt{c4}.}
    \label{fig:smape_c4}
\end{figure}

Podemos observar que el SMAPE tiene un valle entre los datos $[20-50]$ y $[200-300]$ tC/ha, donde llega a ser inferior al $30\%$ para los mejores modelos. Atendiendo a la distribución de los datos de entrenamiento en la Figura~\ref{fig:smape_c4} nos damos cuenta de que para valores pequeños ($[0-20]$ tC/ha) el SMAPE es alto pese a que en ese rango se encuentra prácticamente la mitad de los datos de entrenamiento, lo que indica que el error medio del modelo no es lo suficientemente pequeño como para hacer predicciones confiables para cultivos pequeños. Tras el punto inicial el SMAPE disminuye rápidamente mientras el RMSE aumenta ligeramente. Este comportamiento se mantiene durante la zona valle, lo que indica que, si bien el error absoluto aumenta, no lo hace tanto el error relativo. Esto es un indicativo de que es esta zona el modelo comprende mejor el comportamiento de los datos. El SMAPE comienza a aumentar rápidamente a partir del rango $[150-200]$ tC/ha, valor que coincide con una gran escasez de datos comparado con el resto de rangos.

Para comprobar que los modelos están aprendiendo la lógica del crecimiento de los árboles (cuanto más tiempo, más carbono absobido) podemos hacer la simulación de predecir el carbono para un mismo cultivo a los largo de todos los años disponibles. Esta prueba se ha realizado en la Figura \ref{fig:prediccion_vs_periodo_top5} para el caso del modelo LightGBM. Se encogieron las cinco especies más comunes del dataset junto con sus valores más comunes de los datos de entrada (la media para los parámetros numéricos, la moda para los categóricos) y se realizó la predicción cambiando únicamente el año de predicción. Observamos que el carbono aumenta a medida que lo hace el tiempo, lo que indica que la lógica del modelo es la esperada.

\begin{figure}
      \centering
      \includegraphics[width=0.8\textwidth]{figuras/prediccion_vs_periodo_top5.pdf}
      \caption{Valor de carbono en función del tiempo para los cinco cultivos más comunes del dataset para el modelo LightGBM.}
      \label{fig:prediccion_vs_periodo_top5}
\end{figure}







\hline 

% esto ya son resultados
Los resultados recogidos en la Tabla~\ref{tab:stack_ifn2_ifn3c} muestran que el \textit{stacking} ofrece un rendimiento comparable al de los mejores modelos individuales basados en árboles y \textit{gradient boosting}. En concreto, mientras que CatBoost obtiene un $R^2$ de 0.78 y un RMSE de 22.99 tC/ha, las configuraciones de \textit{stacking} alcanzan valores similares, con $R^2$ en torno a 0.79 y RMSE cercano a 22.39 tC/ha en el mejor caso (\texttt{stack5\_MLP}).


En general, la agregación de modelos mediante \textit{GradientBoosting} como meta-modelo no produce mejora en los
resultados, lo que sugiere que la mezcla de arquitecturas distintas es más beneficiosa.

El rendimiento del \textit{stacking} depende de manera importante del meta-modelo empleado. En
primer lugar, los modelos lineales (Regresión Lineal y Ridge) ofrecen, de forma sistemática,
un rendimiento sólido y muy estable en todas las configuraciones, situándose casi siempre entre
las mejores alternativas dentro de cada grupo de \texttt{stack\_configs}. Esto sugiere que,
dado el reducido número de meta-predictores (salidas de los modelos base), una combinación
esencialmente lineal es suficiente para explotar gran parte de la información disponible sin
incurrir en sobreajuste.

En contraste, los meta-modelos basados en \textit{Random Forest} muestran de manera consistente
los peores resultados dentro de cada configuración. Este comportamiento indica que, sobre un espacio
de baja dimensión, una capacidad excesiva de modelado no aporta beneficios y tiende más bien a
ajustar ruido en las predicciones de los modelos base.

Los meta-modelos no lineales más sencillos, como MLP y SVR,
proporcionan mejoras puntuales sobre los lineales. Destaca especialmente la configuración
\texttt{stack5\_MLP}, que alcanza el valor más alto de $R^2$ (0.79) junto con el menor
RMSE (22.39 tC/ha) de todas las combinaciones evaluadas. En conjunto, estos resultados indican que existe una ligera
ganancia al introducir cierta no linealidad en la combinación de las predicciones base, pero
que dicha ganancia se produce sólo cuando el modelo de segundo nivel mantiene una complejidad
moderada y bien regularizada.

% \subsubsection{Toneladas de carbono}

% La Tabla~\ref{tab:stack_ifn2_ifn3_tc} muestra los resultados del \textit{stacking} para la
% predicción de la variable \texttt{carbono\_bruto4} (toneladas de carbono absolutas).



% Los resultados del \textit{stacking} para la variable de carbono en toneladas muestran un patrón
% similar al observado para la variable en tC/ha. El mejor modelo es nuevamente \texttt{stack5\_MLP},
% que alcanza un $R^2 = 0.85$ y un RMSE de 13.76 tC, superando ligeramente al mejor modelo
% individual (CatBoost, con RMSE = 13.85 tC).

\subsection{Discusión sobre la variable objetivo \texttt{carbono\_bruto\_4}}

Para el caso de los modelos individuales, para la variable \texttt{carbono\_bruto\_4} el modelo CatBoost con un $R^2 = 0.8448$ supera ligeramente a LightGBM, que era el que mejor $R^2$ obtenía para la variable \texttt{c4}. Así mismo, el modelo CatBoost también es el que presenta un menor RMSE ($13.85$ tC) y un menor MAE ($6.6148$ tC). Si hacemos la comparación de las métricas entre los modelos que predices \texttt{c4} y \texttt{carbono\_bruto\_4} observamos que los $R^2$ mejoran de forma sistemática para la variable \texttt{carbono\_bruto\_4}, lo que sugiere que es más sencillo predecir la variable objetivo en toneladas de carbono.

Podemos observar los valores predichos contra los reales en la figura \ref{fig:density_CatBoost_0-300}. Observamos un caso muy similar a aquel observado para la variable \texttt{c4}, con un rango de valores posibles muy grande (de $0$ a $300$ tC) situandose la gran mayoría en el rango entre $0$ y $100$ tC. También ocurre que la mayor densidad de puntos se encuentra en valores pequeños, además de que la línea de mayor densidad se encuentra cercana a la línea de predicción correcta, lo que indica que el modelo capta de forma correcta la tendencia de los datos.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figuras/density_CatBoost_0-300.pdf}
    \caption{Densidad de la variable \texttt{carbono\_bruto\_4} para el modelo CatBoost. Solo se muestran los valores entre 0 y 300 tC.}
    \label{fig:density_CatBoost_0-300}
\end{figure}
    
De igual forma, en la Figura \ref{fig:carbono_bruto_4_SMAPE_RMSE} se muestran los valores de SMAPE y RMSE de los modelos individuales para distintos rangos de valores de la variable objetico \texttt{carbono\_bruto\_4}. De nuevo, el comportamiento es similar al observado para la variable \texttt{c4}, pudiendo observar un valle en el SMAPE entre los rangos $[20-50]$ tC y $[200-300]$ tC, mientras que en el RMSE aumenta a medida que el valor de la variable objetivo aumenta. Esto sugiere que las mejores predicciones son aquellas dentro del rango de valores del valle, donde el error porcentual es menor (llegando a cerca del $25\%$ de error para el rango $[100-150]$ tC). Un mayor valor del error en valores extremos de la variable objetico sugiere que los modelos no pueden alcanzar la suficiente precisión como para ser útil en valores de carbono pequeños (donde un error ``pequeño'' penaliza en mayor medida que para valores de carbono altos), bien porque los modelos no son suficeintemente bueno o bien por la elevada variabilidad de los datos. Para valores de carbono altos el error elevado se debe muy posiblemente a la poca cantidad de datos disponibles.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figuras/carbono_bruto4_base_models_SMAPE_RMSE_combined_bins.pdf}
    \caption{SMAPE y RMSE de los modelos base para la variable \texttt{carbono\_bruto\_4}.}
    \label{fig:carbono_bruto_4_SMAPE_RMSE}
\end{figure}
    


\subsection{Síntesis de resultados}
\label{subsec:resultados_sintesis}

A partir del análisis realizado, pueden resumirse las principales conclusiones en los siguientes puntos:

\begin{itemize}
    \item El conjunto de datos depurado muestra una variables objetivos marcadas con gran variabilidad:
          \texttt{carbono\_bruto4} presenta menor dispersión (SD $\approx 36$ tC/ha)
          que \texttt{c4} (SD $\approx 47$ tC/ha), lo que anticipa un problema predictivo más complejo
          para esta última.

    \item El análisis ANOVA confirma que el \textit{periodo} tiene un efecto estadísticamente
          significativo sobre ambas variables de carbono, evidenciando la existencia de variaciones
          temporales sistemáticas relevantes para su modelización.

    \item Entre las estrategias de selección de variables evaluadas (manual, FeatureWiz y mRMR),
          la selección manual, basada en bloques temáticos con coherencia ecológica, ofrece el mejor
          equilibrio entre simplicidad y rendimiento, superando en precisión y error a las selecciones
          automáticas.

    \item Los bloques de variables más informativos son, en orden aproximado de importancia:
          estructura de la masa forestal, características de especie, condiciones edáficas y topográficas,
          índices de vegetación e información climática estacional. La mayor parte del poder predictivo se
          concentra en las características estructurales y de especie.

    \item Los modelos individuales muestran que los métodos basados en árboles y
          \textit{gradient boosting} (CatBoost, LightGBM, XGBoost y GBDT) alcanzan el mejor rendimiento
          global, con valores de $R^2$ superiores a 0.79 y errores moderados (inferiores al $50\%$ de
          la desviación típica de la variable).

    \item CatBoost destaca como el mejor modelo individual, gracias a su capacidad para capturar
          relaciones no lineales y manejar adecuadamente la complejidad y heterogeneidad de los datos.

    \item Métodos como AdaBoost, KNN o BayesianNN muestran un rendimiento sustancialmente inferior,
          lo que los descarta como candidatos eficaces para este tipo de predicción.

    \item Las técnicas de \textit{stacking} mejoran de forma consistente el rendimiento de los
          modelos individuales, alcanzando la mejor configuración (el metamodelo SVR con los modelos
          \texttt{CatBoost, Random Forest, GBDT}) un $R^2$ de 0.86 y reduciendo el RMSE y el MAE
          frente a CatBoost en un $20.26\%$ y en un $23.16\%$ respectivamente.

    \item El rendimiento del ensamble depende del meta-modelo: los modelos lineales
          (Regresión Lineal y Ridge) ofrecen combinaciones estables y robustas; los meta-modelos Random
          Forest tienden al sobreajuste; y los meta-modelos moderadamente no lineales (SVR y MLP)
          proporcionan las mayores mejoras, destacando SVR en las configuraciones \texttt{stack3} y
          \texttt{stack4}.

    \item En conjunto, los resultados muestran que la combinación de modelos mediante
          \textit{stacking}, aplicada con meta-modelos bien regularizados, permite aprovechar la
          complementariedad entre los distintos algoritmos y alcanzar una capacidad predictiva superior
          a la de cualquier modelo individual.

    \item El modelo desarrollado es capaz de predecir, a partir de las características estructurales,
          ecológicas y ambientales de un cultivo forestal, la cantidad de carbono almacenado por hectárea
          en un horizonte temporal de entre 4 y 35 años con un nivel elevado de precisión.
          El mejor modelo obtenido se construye mediante un metamodelo \texttt{SVR} combinando los modelos
          \texttt{CatBoost, Random Forest} y \texttt{GBDT} y alcanza un coeficiente de determinación de
          \textbf{$R^2 = 0.8604$}, junto con un error típico de \textbf{RMSE = 17.22 tC/ha} y un error
          medio absoluto de \textbf{MAE = 8.78 tC/ha}.
\end{itemize}
