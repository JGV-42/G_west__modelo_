\section{Discusión}
\label{sec:discusion}

\vspace{1cm}
\hline
\vspace{1cm}

Por simplicidad se hará la discusión únicamente para los modelos entrenados con los datos del IFN2 y el IFN3. Esto es porque se puede comprobar que estos modelos se reducen al modelo con el IFN2 cuando los datos de entrada (se ha comprobado con el test) proceden del IFN3 (las métricas son ligeramente peores por la ``contaminación'' de los datos del IFN2, pero en esencia se comportan de la misma manera). Además, como se verá en los siguientes apartados, la distinción entre cuándo el modelo obtiene la información de un modelo o de otro está muy clara en las métricas.

\subsection{Variable \textttt{c4} (en toneladas de carbono por hectárea)}

\subsubsection{Modelos base}

La variable \texttt{periodo} (el número de años entre la medición y la predicción) tiene una gran importancia en el estudio de los modelos. Es por esto que en las Figuras \ref{fig:LightGBM_rmse_cuantiles} y \ref{fig:LightGBM_rmse_porcentual_cuantiles} se incluyen métricas en función de esta variable. En la Figura \ref{fig:LightGBM_rmse_cuantiles} se muestra la evolución del RMSE en cuantiles en función de la variable \texttt{periodo}, junto con un histograma que nos permite visualizar la cantidad de datos en el conjunto de entrenamiento para cada valor de \texttt{periodo}. A su vez, la Figura \ref{fig:LightGBM_rmse_porcentual_cuantiles} es muy similar pero mostrando el RMSE porcentual en cuantiles en función de la variable \texttt{periodo}.

TODO: colorear las barras del hostograma según el origen de cada punto en función si viene del IFN2 o 3
TODO: añadir medias
\begin{figure}
      \centering
      \includegraphics[width=0.8\textwidth]{figuras/LightGBM_rmse_cuantiles.pdf}
      \caption{Evolución del RMSE en cuantiles en función de la variable \texttt{periodo} para el modelo LightGBM con IFN2 e IFN3 como explicativos.}
      \label{fig:LightGBM_rmse_cuantiles}
\end{figure}

\begin{figure}
      \centering
      \includegraphics[width=0.8\textwidth]{figuras/LightGBM_pct_rmse_cuantiles.pdf}
      \caption{Evolución del RMSE porcentual en cuantiles en función de la variable \texttt{periodo} para el modelo LightGBM con IFN2 e IFN3 como explicativos.}
      \label{fig:LightGBM_rmse_porcentual_cuantiles}
\end{figure}
  
Tanto en la Figura \ref{fig:LightGBM_rmse_cuantiles} como en la Figura \ref{fig:LightGBM_rmse_porcentual_cuantiles} se observa el mismo comportamiento: las mejores mediciones se obtienen aquellos casos en los que los datos de entrenamiento provienen del IFN3. Esto se ve claramente en la forma en la que aumentan los errores (sobre todo los del cuantil $90$) cuando se intenta predecir valores para un periodo mayor a $17$ años, valor a partir del cuál los datos del IFN3 se acaban. Observamos que a partir de los $17$ años aumenta en gran medida los valores grandes de error (cuantil $90$) junto con los valores grandes - medios (cuantil $75$). No obstante, los valores medianos y los pequeños - medios (cuantil $25$) se mantienen relativamente estables, aumentando ligeramente con el periodo.

En las Figuras observamos algo que podíamos preveer: la dificultad de la predicción depende de una combinación entre cómo de lejos quieres hacer la predicción y la calidad de los datos de entrenamiento. Empezando en terreno del IFN3, podemos observar que para los primeros años ($5$, y $6$), pese a tener pocos datos, los errores son relativamente comedidos A medida que aumenta el periodo (entre $10$ y $17$ años) los errores se mantienen relaticamente estables pase a disponer de, en general, más datos de entrenamiento. Cuando entramos en el rango de años donde los datos de entrenamiento proceden del IFN2 principalmente (el rando entre $20$ y $30$ años), aunque la mediana y los valores pequeños - medios (cuantil $25$) se mantienen relativamente estables, los valores grandes - medios (cuantil $75$) y los grandes (cuantil $90$) aumentan en gran medida. Esto es un indicativo de que, aún disponiendo de una gran cantidad de datos de entrenamiento (especialmente para los años $27$ y $28$), la combinación entre la peor calidad de los datos (comparando siempre con el IFN3) y la predicción a valores lejanos dificulta en gran medida la predicción del modelo.



\subsection{Conjunto de datos de entrenamiento}
TODO: Revisar teiendo en cuenta los resultados completos
Uno de los resultados más consistentes del presente trabajo es que los modelos entrenados utilizando exclusivamente el IFN3 como conjunto de variables explicativas alcanzan un rendimiento sistemáticamente superior al de aquellos entrenados de forma conjunta con IFN2 e IFN3, tanto para la predicción del carbono total (tC) como del carbono normalizado por superficie (tC/ha). Esta mejora se manifiesta de forma clara en valores más elevados de $R^2$ y en reducciones apreciables de las métricas de error (RMSE y MAE), y se observa de manera estable en todos los algoritmos evaluados.

Una explicación plausible de este comportamiento está relacionada con la calidad y homogeneidad de los datos. El IFN3 fue realizado aproximadamente una década después del IFN2, incorporando avances metodológicos y tecnológicos relevantes en la recogida de información de campo, así como protocolos más refinados para la medición de variables estructurales y de estado de las masas forestales. A esto se une el aumento de variables que se miden en cada apeo de las parcelas. Esta mayor precisión y cantidad en las variables explicativas reduce el ruido inherente al proceso de modelización y facilita el aprendizaje de relaciones más consistentes entre predictores y variable objetivo. En este contexto, la inclusión de datos procedentes del IFN2 podría introducir heterogeneidad adicional asociada a diferencias metodológicas entre inventarios, lo que penaliza el rendimiento predictivo global.

Por otro lado, el número de observaciones disponibles para el entrenamiento difiere entre configuraciones. El entrenamiento exclusivo con datos del IFN3 se realiza sobre un conjunto de menor tamaño y que, además, incorpora filtros de calidad más estrictos, (filtro por \texttt{fccarb}$>20$), que no está disponible en el IFN2. A pesar de estas diferencias en tamaño muestral y criterios de selección, los resultados no muestran indicios de sobreajuste en ninguno de los casos. 

En conjunto, estos resultados ponen de manifiesto que, en este caso de estudio, la calidad y coherencia temporal del inventario parecen tener un impacto más relevante en el rendimiento predictivo que la simple agregación de información procedente de inventarios previos. Este hallazgo es especialmente relevante de cara a futuras aplicaciones operativas, ya que sugiere que modelos entrenados sobre inventarios recientes y metodológicamente homogéneos pueden ofrecer estimaciones más precisas y fiables del carbono forestal, incluso cuando se dispone de menos fuentes de información histórica.

A modo de conclusión, los resultados obtenidos indican que la elección del conjunto de entrenamiento debe adaptarse al horizonte temporal de predicción considerado. En particular, el modelo entrenado exclusivamente con datos del IFN3 resulta más adecuado para predicciones a medio plazo, en un horizonte temporal aproximado de entre 9 y 17 años, donde la mayor calidad y coherencia metodológica de este inventario se traduce en estimaciones más precisas y estables del carbono forestal. Por el contrario, cuando el objetivo es realizar predicciones a más largo plazo, con horizontes temporales superiores y que pueden extenderse hasta los 30 años, el uso combinado de datos procedentes del IFN2 y del IFN3 se hace obligatorio, ya que ofrece una base temporal más amplia que permite capturar mejor la evolución de las masas forestales en periodos prolongados. En este contexto, aunque el rendimiento predictivo sea ligeramente inferior, la integración de ambos inventarios aporta robustez frente a escenarios de extrapolación temporal, lo que hace recomendable su empleo para proyecciones de largo plazo.

\subsection{Variable objetivo}
En la interpretación de los resultados es fundamental contextualizar la diferencia entre las dos variables objetivo empleadas en el estudio: el carbono expresado en toneladas absolutas (\texttt{tC}) y el carbono normalizado por superficie (\texttt{tC/ha}). Tal y como se observa en la Tabla~\ref{tab:resumen_variables}, la variable \texttt{carbono_bruto4} (tC) muestra una media inferior, pero una elevada dispersión relativa, con un rango amplio y valores extremos asociados a parcelas con estructuras muy heterogéneas. Por su parte, la variable \texttt{c4} (tC/ha) presenta una media más alta y una variabilidad absoluta mayor.

Estas diferencias estructurales tienen implicaciones directas sobre la capacidad predictiva de los modelos. En términos generales, la variable expresada en tC resulta más sencilla de modelizar, ya que integra implícitamente la superficie y reduce parte de la variabilidad introducida por la normalización por hectárea. Como consecuencia, los modelos entrenados para predecir carbono total alcanzan sistemáticamente valores más altos de $R^2$ y errores más bajos (RMSE y MAE) que aquellos orientados a la predicción de tC/ha. Esto indica que una mayor fracción de la varianza es explicada por las variables explicativas disponibles cuando la respuesta se expresa en términos absolutos.

En cambio, la predicción en tC/ha constituye un problema más exigente desde el punto de vista estadístico, al amplificar la heterogeneidad intra-parcela y la influencia de factores locales no completamente capturados por los predictores. No obstante, esta variable resulta especialmente relevante para aplicaciones de comparación espacial, evaluación de productividad y análisis de eficiencia en el secuestro de carbono, lo que justifica su inclusión a pesar de presentar métricas de ajuste ligeramente inferiores. En conjunto, los resultados ponen de manifiesto que la elección de la variable objetivo debe alinearse con el objetivo final del análisis, asumiendo el compromiso existente entre interpretabilidad ecológica y rendimiento predictivo.

\subsection{Distribución del error}
El análisis conjunto de las métricas globales de los modelos predictivos muestra de forma consistente que el valor del RMSE es aproximadamente el doble del MAE. Dado que el RMSE penaliza de manera más severa los errores de gran magnitud, esta diferencia indica que, aunque el error medio absoluto se mantiene en niveles moderados, existen observaciones concretas en las que los modelos cometen desviaciones significativamente mayores.

Este patrón sugiere que la dificultad predictiva no es homogénea a lo largo de todo el rango de la variable objetivo, sino que se concentra en determinados valores o contextos específicos. En este sentido, resulta necesario complementar la evaluación con métricas relativas como el SMAPE, que permiten analizar el error en proporción a la magnitud de la variable, así como con representaciones gráficas —como los diagramas de dispersión entre valores observados y predichos— que facilitan la identificación visual de sesgos, heterocedasticidad o rangos problemáticos del modelo.

En la Figura~\ref{fig:dispersion_densidad_c4} se representa la dispersión entre los valores observados y las predicciones obtenidas por el modelo LightGBM (el de mayor R$^2$) para la variable objetivo \texttt{c4} (tC/ha)empleando como explicativos los inventarios IFN2 y IFN3. También se incluye un histograma de la densidad de puntos.

TODO: hace falta otra igual para carbono_bruto4. No se que modelo es el de la foto. Actualizar la imagen. Poner el caption de la foto en CASTELLANO.

Aunque \texttt{c4} presenta un rango muy amplio, desde valores próximos a cero hasta aproximadamente $880$~tC/ha, la figura pone de manifiesto que la mayor concentración de observaciones se sitúa en el intervalo comprendido entre $0$ y $200$~tC/ha. En este rango, que además concentra la mayor parte de la masa de datos, la nube de puntos se alinea de forma clara en torno a la diagonal identidad.

Si bien existen casos puntuales en los que las predicciones se desvían notablemente de los valores reales, especialmente en los extremos superiores del rango, la estructura general del gráfico indica que el modelo reproduce de manera consistente la relación media entre valores observados y predichos. Este comportamiento es coherente con la diferencia observada entre RMSE y MAE, y refuerza la idea de que los errores más elevados se concentran en un subconjunto reducido de observaciones, mientras que el ajuste es sólido en las regiones donde se acumula la mayor densidad de datos.

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{figuras/density_LightGBM_0-300.pdf}
\caption{Dispersión de las predicciones frente a los valores reales para la variable objetivo \texttt{c4}. Se representa únicamente el rango $[0,300]$~tC.}
\label{fig:dispersion_densidad_c4}
\end{figure}

Este comportamiento se analiza de forma explícita en la Figura~\ref{fig:smape_c4}, donde se representan, por intervalos de la variable objetivo \texttt{c4}, los valores de SMAPE y RMSE obtenidos por los distintos modelos base, junto con un histograma que muestra el número de observaciones disponibles en cada rango. Esta figura permite evaluar simultáneamente la magnitud del error y su dependencia de la densidad de datos a lo largo del dominio de la variable.

Los resultados confirman que el error relativo no es homogéneo. En los rangos intermedios de carbono, donde existe una combinación favorable de volumen de datos, comportamiento más estable del sistema y una cantidad de carbono suficientemente grande como para permitir un margen de error razonable (no es lo mismo un error de una toneladas en una parcela de 2 toneladas totales que en otra de 100 toneladas), el SMAPE alcanza valores mínimos, bajando del $20\%$ de error. En cambio, para valores bajos de \texttt{c4}, el SMAPE es elevado pese a la abundancia de observaciones, lo que refleja una alta variabilidad relativa en este régimen y una mala precisión de los modelos. Finalmente, en los valores más altos de carbono, el incremento del SMAPE coincide con una fuerte reducción del número de datos, evidenciando que la escasez de observaciones en los extremos de la distribución limita la capacidad de generalización del modelo.

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{figuras/c4_base_models_SMAPE_RMSE_combined_bins.pdf}
\caption{SMAPE y RMSE por rangos de la variable objetivo \texttt{c4} para los modelos base, junto con la distribución del número de observaciones en cada intervalo.}
\label{fig:smape_c4}
\end{figure}

TODO: Tal vez conviene hablar aqui sobre como de bien predice según PERIODO. Un grafico y tal. 

